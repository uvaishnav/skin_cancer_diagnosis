{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Volumes/T7/DL_Skin_Cancer_Project/skin_cancer_diagnosis'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"../\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting Environment Variables for ML flow\n",
    "\n",
    "MLFLOW_TRACKING_URI=https://dagshub.com/uvaishnav/skin_cancer_diagnosis.mlflow \\\n",
    "MLFLOW_TRACKING_USERNAME=uvaishnav \\\n",
    "MLFLOW_TRACKING_PASSWORD=490c4cfe721d1b436d9c273a74eb000830a68aab \\\n",
    "python script.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['MLFLOW_TRACKING_URI']= 'https://dagshub.com/uvaishnav/skin_cancer_diagnosis.mlflow'\n",
    "os.environ['MLFLOW_TRACKING_USERNAME'] = 'uvaishnav'\n",
    "os.environ['MLFLOW_TRACKING_PASSWORD'] = '490c4cfe721d1b436d9c273a74eb000830a68aab'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skinCancerDiagnosis.entity.config_entity import ModelevalConfig\n",
    "from skinCancerDiagnosis.config.configuration import ConfugarationManager\n",
    "from skinCancerDiagnosis.components.data_prep import DataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.keras\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluation:\n",
    "    def __init__(self, config:ModelevalConfig) :\n",
    "        self.config = config\n",
    "\n",
    "    @staticmethod\n",
    "    def load_model(path:Path)-> tf.keras.Model:\n",
    "        return load_model(path)\n",
    "\n",
    "    def evaluate_model(self,test_generator):\n",
    "        self.model = self.load_model(self.config.model_path)\n",
    "\n",
    "        # Get loss and acuracy\n",
    "        self.score = self.model.evaluate(test_generator)\n",
    "        \n",
    "        # Generate predictions on the test data generator\n",
    "        y_pred_prob = self.model.predict(test_generator)\n",
    "        y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "        # Retrieve true labels from the test data generator\n",
    "        y_true = test_generator.classes\n",
    "\n",
    "        # Compute Micro-average Precision, Recall, and F1-Score\n",
    "        self.micro_precision = precision_score(y_true, y_pred, average='micro')\n",
    "        self.micro_recall = recall_score(y_true, y_pred, average='micro')\n",
    "        self.micro_f1_score = f1_score(y_true, y_pred, average='micro')\n",
    "\n",
    "    def log_into_mlflow(self,model_name):\n",
    "        mlflow.set_registry_uri(self.config.mlflow_uri)\n",
    "        tracking_url_type_store = urlparse(mlflow.get_tracking_uri()).scheme\n",
    "\n",
    "        with mlflow.start_run():\n",
    "            mlflow.log_params(self.config.all_params)\n",
    "            mlflow.log_metrics(\n",
    "                {\n",
    "                    \"loss\" : self.score[0],\n",
    "                    \"accuracy\" : self.score[1],\n",
    "                    \"micro_precision\" : self.micro_precision,\n",
    "                    \"micro_recall\" : self.micro_recall,\n",
    "                    \"micro_f1\" : self.micro_f1_score\n",
    "                }\n",
    "            )\n",
    "            # Model registry does not work with file store\n",
    "            if tracking_url_type_store != \"file\":\n",
    "                logging.info(\"regestiring Model to MLFlow\")\n",
    "                mlflow.keras.log_model(self.model, \"model\", registered_model_name=model_name)\n",
    "            else:\n",
    "                mlflow.keras.log_model(self.model, \"model\")\n",
    "                logging.info(\"Inable to regestitor model to mlflow\")\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Evaluation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-04-23 23:13:21,591: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
      "[2024-04-23 23:13:21,593: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-04-23 23:13:21,594: INFO: common: created directory at: artifacts]\n",
      "Found 1930 images belonging to 8 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-23 23:13:21.788302: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2024-04-23 23:13:21.788321: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2024-04-23 23:13:21.788328: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2024-04-23 23:13:21.788345: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-04-23 23:13:21.788355: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-04-23 23:13:22,182: WARNING: saving_utils: Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-23 23:13:22.926293: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n",
      "/Volumes/T7/DL_Skin_Cancer_Project/canserenv/lib/python3.9/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 682ms/step - accuracy: 0.3469 - loss: 2.4684\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 682ms/step\n",
      "[2024-04-23 23:14:49,451: INFO: 3261167456: regestiring Model to MLFlow]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/04/23 23:14:49 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "/Volumes/T7/DL_Skin_Cancer_Project/canserenv/lib/python3.9/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
      "Successfully registered model 'VGG19'.\n",
      "2024/04/23 23:15:18 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: VGG19, version 1\n",
      "Created version '1' of model 'VGG19'.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfugarationManager()\n",
    "    \n",
    "    data_prep_config = config.get_data_prep_config()\n",
    "    generator = DataGenerator(config=data_prep_config)\n",
    "    test_generator = generator.get_test_generator()\n",
    "\n",
    "    vgg_eval_config = config.get_evaluation_config(model_path='vgg19.h5')\n",
    "    vgg_evaluator = Evaluation(vgg_eval_config)\n",
    "    vgg_evaluator.evaluate_model(test_generator=test_generator)\n",
    "    vgg_evaluator.log_into_mlflow(model_name=\"VGG19\")\n",
    "    \n",
    "except Exception as e:\n",
    "    raise e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
